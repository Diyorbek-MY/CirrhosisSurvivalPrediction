{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":83459,"databundleVersionId":9248778,"sourceType":"competition"}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.041246Z","iopub.execute_input":"2025-06-12T18:12:44.041632Z","iopub.status.idle":"2025-06-12T18:12:44.049789Z","shell.execute_reply.started":"2025-06-12T18:12:44.041599Z","shell.execute_reply":"2025-06-12T18:12:44.048878Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/multiclassificationtask/sample_submission.csv\n/kaggle/input/multiclassificationtask/train.csv\n/kaggle/input/multiclassificationtask/test.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.051046Z","iopub.execute_input":"2025-06-12T18:12:44.051327Z","iopub.status.idle":"2025-06-12T18:12:44.346252Z","shell.execute_reply.started":"2025-06-12T18:12:44.051299Z","shell.execute_reply":"2025-06-12T18:12:44.345198Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load the Dataset","metadata":{}},{"cell_type":"code","source":"sample_submission_path = \"/kaggle/input/multiclassificationtask/sample_submission.csv\"\ntest_path = \"/kaggle/input/multiclassificationtask/test.csv\"\ntrain_path = \"/kaggle/input/multiclassificationtask/train.csv\"\n\nsample_submission_df = pd.read_csv(sample_submission_path)\ntest_df = pd.read_csv(test_path)\ntrain_df = pd.read_csv(train_path)\n\n\nprint(\"Train data shape:\", train_df.shape)\nprint(\"Test data shape:\", test_df.shape)\nprint(\"Sample Submission shape:\", sample_submission_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.347950Z","iopub.execute_input":"2025-06-12T18:12:44.348876Z","iopub.status.idle":"2025-06-12T18:12:44.478814Z","shell.execute_reply.started":"2025-06-12T18:12:44.348838Z","shell.execute_reply":"2025-06-12T18:12:44.477794Z"}},"outputs":[{"name":"stdout","text":"Train data shape: (15000, 20)\nTest data shape: (10000, 19)\nSample Submission shape: (10000, 4)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Data Analysis","metadata":{}},{"cell_type":"code","source":"# Display the first few rows of the training data\nprint(\"Train DataFrame Head:\")\nprint(train_df.head())\n\n# Display information about the DataFrame (data types, non-null counts)\nprint(\"\\nTrain DataFrame Info:\")\ntrain_df.info()\n\n# Display descriptive statistics of numerical columns\nprint(\"\\nTrain DataFrame Description:\")\nprint(train_df.describe())\n\n# Check the distribution of the target variable\nprint(\"\\nDistribution of 'Status' in Train DataFrame:\")\nprint(train_df['Status'].value_counts())\nprint(\"\\nProportion of 'Status' in Train DataFrame:\")\nprint(train_df['Status'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.479730Z","iopub.execute_input":"2025-06-12T18:12:44.479979Z","iopub.status.idle":"2025-06-12T18:12:44.571415Z","shell.execute_reply.started":"2025-06-12T18:12:44.479960Z","shell.execute_reply":"2025-06-12T18:12:44.570413Z"}},"outputs":[{"name":"stdout","text":"Train DataFrame Head:\n   id  N_Days             Drug      Age Sex Ascites Hepatomegaly Spiders  \\\n0   0  2178.0  D-penicillamine  16374.0   F       N            N       N   \n1   1  2644.0  D-penicillamine  17774.0   F       N            N       N   \n2   2  3069.0          Placebo  17844.0   F       N            N       N   \n3   3  2216.0          Placebo  19221.0   F       N            Y       Y   \n4   4  2256.0          Placebo  21600.0   F       N            N       N   \n\n  Edema  Bilirubin  Cholesterol  Albumin  Copper  Alk_Phos    SGOT  \\\n0     N        0.5        263.0     3.20    43.0    1110.0  106.95   \n1     N        0.8        280.0     3.60    22.0     678.0   62.00   \n2     N        1.1        408.0     4.40    54.0    2108.0  142.60   \n3     N        0.8        252.0     3.70    36.0     843.0   55.80   \n4     N        4.7        348.0     3.06   464.0     961.0  120.90   \n\n   Tryglicerides  Platelets  Prothrombin  Stage Status  \n0           67.0      430.0          9.6    3.0      C  \n1           80.0      427.0         13.0    3.0      C  \n2          137.0      203.0         10.6    3.0      C  \n3           56.0      336.0          9.6    4.0      C  \n4          146.0      298.0         11.0    2.0      D  \n\nTrain DataFrame Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 15000 entries, 0 to 14999\nData columns (total 20 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   id             15000 non-null  int64  \n 1   N_Days         15000 non-null  float64\n 2   Drug           8494 non-null   object \n 3   Age            15000 non-null  float64\n 4   Sex            15000 non-null  object \n 5   Ascites        8502 non-null   object \n 6   Hepatomegaly   8492 non-null   object \n 7   Spiders        8491 non-null   object \n 8   Edema          15000 non-null  object \n 9   Bilirubin      15000 non-null  float64\n 10  Cholesterol    6701 non-null   float64\n 11  Albumin        15000 non-null  float64\n 12  Copper         8399 non-null   float64\n 13  Alk_Phos       8488 non-null   float64\n 14  SGOT           8486 non-null   float64\n 15  Tryglicerides  6666 non-null   float64\n 16  Platelets      14436 non-null  float64\n 17  Prothrombin    14984 non-null  float64\n 18  Stage          15000 non-null  float64\n 19  Status         15000 non-null  object \ndtypes: float64(12), int64(1), object(7)\nmemory usage: 2.3+ MB\n\nTrain DataFrame Description:\n                 id        N_Days            Age     Bilirubin  Cholesterol  \\\ncount  15000.000000  15000.000000   15000.000000  15000.000000  6701.000000   \nmean    7499.500000   1971.721267   19298.658267      1.845433   329.177302   \nstd     4330.271354   1333.733576    3797.580260      2.674859   180.320802   \nmin        0.000000      3.000000     400.000000      0.200000   120.000000   \n25%     3749.750000   1095.000000   16658.000000      0.600000   242.000000   \n50%     7499.500000   1786.000000   19544.000000      0.900000   280.000000   \n75%    11249.250000   2635.000000   22347.000000      1.800000   364.000000   \nmax    14999.000000  38320.000000  129398.000000     28.000000  2078.000000   \n\n            Albumin       Copper      Alk_Phos         SGOT  Tryglicerides  \\\ncount  15000.000000  8399.000000   8488.000000  8486.000000    6666.000000   \nmean       3.526103    75.647339   1618.598233   106.483631     111.387886   \nstd        0.372268    74.830472   1767.240078    57.206017      55.056133   \nmin        0.500000     2.000000      3.400000     0.900000      19.000000   \n25%        3.290000    31.000000    720.000000    71.000000      80.000000   \n50%        3.580000    52.000000   1072.000000    97.650000      99.000000   \n75%        3.770000    89.000000   1664.000000   130.200000     133.000000   \nmax        4.640000   662.000000  13862.400000  2653.000000    1669.000000   \n\n          Platelets   Prothrombin         Stage  \ncount  14436.000000  14984.000000  15000.000000  \nmean     252.917983     10.626111      3.024800  \nstd       94.049175      0.731416      0.871303  \nmin       32.000000      9.000000      1.000000  \n25%      181.000000     10.100000      2.000000  \n50%      248.000000     10.600000      3.000000  \n75%      311.000000     11.000000      4.000000  \nmax     1024.000000     18.000000      4.000000  \n\nDistribution of 'Status' in Train DataFrame:\nStatus\nC     10053\nD      4565\nCL      381\nY         1\nName: count, dtype: int64\n\nProportion of 'Status' in Train DataFrame:\nStatus\nC     0.670200\nD     0.304333\nCL    0.025400\nY     0.000067\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Drop the row where 'Status' is 'Y'\ntrain_df = train_df[train_df['Status'] != 'Y'].copy()\n\n# Drop the 'id' column from the training data\ntrain_df = train_df.drop('id', axis=1)\n\n# Confirm the new shape and status distribution\nprint(\"Train DataFrame Shape after dropping 'Y' status and 'id' column:\", train_df.shape)\nprint(\"\\nNew Distribution of 'Status' in Train DataFrame:\")\nprint(train_df['Status'].value_counts())\nprint(\"\\nNew Proportion of 'Status' in Train DataFrame:\")\nprint(train_df['Status'].value_counts(normalize=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.573087Z","iopub.execute_input":"2025-06-12T18:12:44.574259Z","iopub.status.idle":"2025-06-12T18:12:44.595177Z","shell.execute_reply.started":"2025-06-12T18:12:44.574223Z","shell.execute_reply":"2025-06-12T18:12:44.594395Z"}},"outputs":[{"name":"stdout","text":"Train DataFrame Shape after dropping 'Y' status and 'id' column: (14999, 19)\n\nNew Distribution of 'Status' in Train DataFrame:\nStatus\nC     10053\nD      4565\nCL      381\nName: count, dtype: int64\n\nNew Proportion of 'Status' in Train DataFrame:\nStatus\nC     0.670245\nD     0.304354\nCL    0.025402\nName: proportion, dtype: float64\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"# Handling Missing Values","metadata":{}},{"cell_type":"code","source":"# Identify categorical and numerical columns with missing values (excluding 'id' and 'Status')\n# Re-identifying all column types after dropping 'id' and 'Y' status\ncategorical_cols = train_df.select_dtypes(include='object').columns.tolist()\n# Remove 'Status' from categorical_cols as it's the target\nif 'Status' in categorical_cols:\n    categorical_cols.remove('Status')\n\nnumerical_cols = train_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n\nprint(\"Categorical columns to impute:\", [col for col in categorical_cols if train_df[col].isnull().any()])\nprint(\"Numerical columns to impute:\", [col for col in numerical_cols if train_df[col].isnull().any()])\n\n# Impute categorical columns with 'Missing' category\nfor col in ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders']: # These were identified with many missing values\n    if col in categorical_cols:\n        train_df[col].fillna('Missing', inplace=True)\n        # Apply the same to test_df if it also has these columns (important for consistency)\n        if col in test_df.columns:\n            test_df[col].fillna('Missing', inplace=True)\n\n\n# Impute numerical columns with the median\nfor col in ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']:\n    if col in numerical_cols:\n        median_val = train_df[col].median()\n        train_df[col].fillna(median_val, inplace=True)\n        # Apply the same to test_df using the median calculated from train_df\n        if col in test_df.columns:\n            test_df[col].fillna(median_val, inplace=True)\n\n# Verify that all missing values have been handled\nprint(\"\\nMissing values after imputation (Train DataFrame):\")\nprint(train_df.isnull().sum())\n\n# Also check for test_df\nprint(\"\\nMissing values after imputation (Test DataFrame):\")\nprint(test_df.isnull().sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.595957Z","iopub.execute_input":"2025-06-12T18:12:44.596172Z","iopub.status.idle":"2025-06-12T18:12:44.647772Z","shell.execute_reply.started":"2025-06-12T18:12:44.596155Z","shell.execute_reply":"2025-06-12T18:12:44.646776Z"}},"outputs":[{"name":"stdout","text":"Categorical columns to impute: ['Drug', 'Ascites', 'Hepatomegaly', 'Spiders']\nNumerical columns to impute: ['Cholesterol', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin']\n\nMissing values after imputation (Train DataFrame):\nN_Days           0\nDrug             0\nAge              0\nSex              0\nAscites          0\nHepatomegaly     0\nSpiders          0\nEdema            0\nBilirubin        0\nCholesterol      0\nAlbumin          0\nCopper           0\nAlk_Phos         0\nSGOT             0\nTryglicerides    0\nPlatelets        0\nProthrombin      0\nStage            0\nStatus           0\ndtype: int64\n\nMissing values after imputation (Test DataFrame):\nid               0\nN_Days           0\nDrug             0\nAge              0\nSex              0\nAscites          0\nHepatomegaly     0\nSpiders          0\nEdema            0\nBilirubin        0\nCholesterol      0\nAlbumin          0\nCopper           0\nAlk_Phos         0\nSGOT             0\nTryglicerides    0\nPlatelets        0\nProthrombin      0\nStage            0\ndtype: int64\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_35/4016621765.py:16: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_df[col].fillna('Missing', inplace=True)\n/tmp/ipykernel_35/4016621765.py:19: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df[col].fillna('Missing', inplace=True)\n/tmp/ipykernel_35/4016621765.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  train_df[col].fillna(median_val, inplace=True)\n/tmp/ipykernel_35/4016621765.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\nThe behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n\nFor example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n\n\n  test_df[col].fillna(median_val, inplace=True)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Feature Engineering and Transformation","metadata":{}},{"cell_type":"code","source":"# Convert 'Age' from days to years in both train and test data\ntrain_df['Age'] = train_df['Age'] / 365.25\ntest_df['Age'] = test_df['Age'] / 365.25\n\nprint(\"\\nAge column head after conversion (Train DataFrame):\")\nprint(train_df['Age'].head())\nprint(\"\\nAge column head after conversion (Test DataFrame):\")\nprint(test_df['Age'].head())\n\n# Store 'id' column from test_df for submission\ntest_id = test_df['id']\n\n# Drop 'id' column from test_df as it's not a feature for modeling\ntest_df = test_df.drop('id', axis=1)\n\nprint(\"\\nTest DataFrame Shape after dropping 'id' column:\", test_df.shape)\n\n\n# Identify categorical columns for one-hot encoding (excluding 'Status')\n# Ensure 'Status' is not in this list, as it's our target.\ncategorical_features = train_df.select_dtypes(include='object').columns.tolist()\nif 'Status' in categorical_features:\n    categorical_features.remove('Status')\n\nprint(\"\\nCategorical features to encode:\", categorical_features)\n\n# Apply One-Hot Encoding to categorical features in both train and test data\n# Use pd.get_dummies to convert categorical variables into dummy/indicator variables.\n# handle_unknown='ignore' is important for test data to prevent errors if a category appears in test but not train.\ntrain_df = pd.get_dummies(train_df, columns=categorical_features, drop_first=True) # drop_first avoids multicollinearity\ntest_df = pd.get_dummies(test_df, columns=categorical_features, drop_first=True)\n\n# Align columns - crucial after one-hot encoding, especially if test_df has different categories\n# or missing 'Missing' categories that were present in train_df\ntrain_cols = set(train_df.columns)\ntest_cols = set(test_df.columns)\n\nmissing_in_test = list(train_cols - test_cols)\nif 'Status' in missing_in_test:\n    missing_in_test.remove('Status') # Don't add Status to test_df\n\nfor col in missing_in_test:\n    if col != 'Status': # Ensure we don't add the target column to test_df\n        test_df[col] = 0\n\nmissing_in_train = list(test_cols - train_cols)\nfor col in missing_in_train:\n    train_df[col] = 0\n\n# Ensure the order of columns is the same, except for the 'Status' column in train_df\ncommon_cols = list(set(train_df.columns) & set(test_df.columns))\ntrain_df = train_df[common_cols + ['Status']] # Keep Status at the end for clarity\ntest_df = test_df[common_cols]\n\nprint(\"\\nTrain DataFrame head after One-Hot Encoding:\")\nprint(train_df.head())\nprint(\"\\nTest DataFrame head after One-Hot Encoding:\")\nprint(test_df.head())\nprint(\"\\nTrain DataFrame shape after One-Hot Encoding:\", train_df.shape)\nprint(\"Test DataFrame shape after One-Hot Encoding:\", test_df.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.648786Z","iopub.execute_input":"2025-06-12T18:12:44.649044Z","iopub.status.idle":"2025-06-12T18:12:44.727496Z","shell.execute_reply.started":"2025-06-12T18:12:44.649023Z","shell.execute_reply":"2025-06-12T18:12:44.726443Z"}},"outputs":[{"name":"stdout","text":"\nAge column head after conversion (Train DataFrame):\n0    44.829569\n1    48.662560\n2    48.854209\n3    52.624230\n4    59.137577\nName: Age, dtype: float64\n\nAge column head after conversion (Test DataFrame):\n0    62.001369\n1    52.000000\n2    43.942505\n3    55.726215\n4    64.000000\nName: Age, dtype: float64\n\nTest DataFrame Shape after dropping 'id' column: (10000, 18)\n\nCategorical features to encode: ['Drug', 'Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema']\n\nTrain DataFrame head after One-Hot Encoding:\n   Cholesterol  Stage  Edema_Y    SGOT  Spiders_Y  Tryglicerides  Spiders_N  \\\n0        263.0    3.0    False  106.95      False           67.0       True   \n1        280.0    3.0    False   62.00      False           80.0       True   \n2        408.0    3.0    False  142.60      False          137.0       True   \n3        252.0    4.0    False   55.80       True           56.0      False   \n4        348.0    2.0    False  120.90      False          146.0       True   \n\n   Drug_Placebo  Copper        Age  ...  N_Days  Bilirubin  Ascites_N  Sex_M  \\\n0         False    43.0  44.829569  ...  2178.0        0.5       True  False   \n1         False    22.0  48.662560  ...  2644.0        0.8       True  False   \n2          True    54.0  48.854209  ...  3069.0        1.1       True  False   \n3          True    36.0  52.624230  ...  2216.0        0.8       True  False   \n4          True   464.0  59.137577  ...  2256.0        4.7       True  False   \n\n   Hepatomegaly_Y  Hepatomegaly_N  Alk_Phos  Prothrombin  Drug_Missing  Status  \n0           False            True    1110.0          9.6         False       C  \n1           False            True     678.0         13.0         False       C  \n2           False            True    2108.0         10.6         False       C  \n3            True           False     843.0          9.6         False       C  \n4           False            True     961.0         11.0         False       D  \n\n[5 rows x 24 columns]\n\nTest DataFrame head after One-Hot Encoding:\n   Cholesterol  Stage  Edema_Y    SGOT  Spiders_Y  Tryglicerides  Spiders_N  \\\n0        280.0    4.0    False   97.65      False           99.0      False   \n1        280.0    2.0    False   97.65      False           99.0      False   \n2        460.0    3.0    False  102.30      False          118.0       True   \n3        258.0    2.0    False   70.00      False           83.0       True   \n4        280.0    2.0    False   97.65      False           99.0      False   \n\n   Drug_Placebo  Copper        Age  ...  Edema_S   N_Days  Bilirubin  \\\n0         False    52.0  62.001369  ...    False  22646.0        1.4   \n1         False    52.0  52.000000  ...    False   2149.0        0.9   \n2         False    75.0  43.942505  ...    False   3850.0        1.0   \n3         False    31.0  55.726215  ...    False   2419.0        0.6   \n4         False    52.0  64.000000  ...    False   1086.0        4.4   \n\n   Ascites_N  Sex_M  Hepatomegaly_Y  Hepatomegaly_N  Alk_Phos  Prothrombin  \\\n0      False  False           False           False    1072.0         11.0   \n1      False  False           False           False    1072.0          9.0   \n2       True   True           False            True    2148.0         10.6   \n3       True  False           False            True     642.0         10.8   \n4      False  False           False           False    1072.0         10.3   \n\n   Drug_Missing  \n0          True  \n1          True  \n2         False  \n3         False  \n4          True  \n\n[5 rows x 23 columns]\n\nTrain DataFrame shape after One-Hot Encoding: (14999, 24)\nTest DataFrame shape after One-Hot Encoding: (10000, 23)\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Model Training and Evaluation ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.metrics import log_loss\nimport lightgbm as lgb\nimport numpy as np\n\n# Separate features (X) and target (y)\nX = train_df.drop('Status', axis=1)\ny = train_df['Status']\n\n# Encode the target variable\n# LightGBM can handle categorical targets, but it's often better to encode them numerically for consistency\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Print the mapping of original status to encoded integers\nprint(\"\\nStatus Label Encoding Mapping:\")\nfor i, label in enumerate(label_encoder.classes_):\n    print(f\"{label}: {i}\")\n\n# Scale numerical features (important for many models, though LightGBM is less sensitive)\n# Identify numerical columns in X\nnumerical_features_for_scaling = X.select_dtypes(include=['float64', 'int64', 'uint8']).columns.tolist() # uint8 for dummy variables\n\n# Remove one-hot encoded columns (which are binary and don't need scaling in this context)\n# We can identify them by checking if they contain only 0s and 1s\nbinary_cols = [col for col in numerical_features_for_scaling if X[col].nunique() == 2 and set(X[col].unique()).issubset({0, 1})]\nnumerical_features_to_scale = [col for col in numerical_features_for_scaling if col not in binary_cols]\n\n\nscaler = StandardScaler()\nX[numerical_features_to_scale] = scaler.fit_transform(X[numerical_features_to_scale])\ntest_df[numerical_features_to_scale] = scaler.transform(test_df[numerical_features_to_scale])\n\nprint(\"\\nFeatures after scaling (Train DataFrame head):\")\nprint(X.head())\nprint(\"\\nFeatures after scaling (Test DataFrame head):\")\nprint(test_df.head())\n\n\n# Model Training with Stratified K-Fold Cross-Validation\n# StratifiedKFold ensures that each fold has roughly the same proportion of target labels as the whole dataset.\nNFOLDS = 5\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\n\noof_preds = np.zeros((len(X), len(label_encoder.classes_)))\nsub_preds = np.zeros((len(test_df), len(label_encoder.classes_)))\n\nfor n_fold, (train_idx, valid_idx) in enumerate(folds.split(X, y_encoded)):\n    X_train, y_train = X.iloc[train_idx], y_encoded[train_idx]\n    X_valid, y_valid = X.iloc[valid_idx], y_encoded[valid_idx]\n\n    lgb_params = {\n        'objective': 'multiclass',\n        'num_class': len(label_encoder.classes_),\n        'metric': 'multi_logloss',\n        'boosting_type': 'gbdt',\n        'n_estimators': 1000, # Increased n_estimators, will use early stopping\n        'learning_rate': 0.03,\n        'num_leaves': 20,\n        'max_depth': 5,\n        'seed': 42,\n        'n_jobs': -1,\n        'verbose': -1,\n        'colsample_bytree': 0.7,\n        'subsample': 0.7,\n        'reg_alpha': 0.1,\n        'reg_lambda': 0.1,\n        'random_state': 42,\n    }\n\n    model = lgb.LGBMClassifier(**lgb_params)\n\n    model.fit(X_train, y_train,\n              eval_set=[(X_valid, y_valid)],\n              callbacks=[lgb.early_stopping(100, verbose=False)]) # Early stopping if validation metric doesn't improve for 100 rounds\n\n    oof_preds[valid_idx] = model.predict_proba(X_valid)\n    sub_preds += model.predict_proba(test_df) / folds.n_splits\n\nprint(f\"\\nOverall OOF LogLoss: {log_loss(y_encoded, oof_preds)}\")\n\n# Create the submission file\nsubmission_df = pd.DataFrame({'id': test_id})\n# Map encoded predictions back to original status labels for submission\nsubmission_df['Status_C'] = sub_preds[:, label_encoder.transform(['C'])[0]]\nsubmission_df['Status_CL'] = sub_preds[:, label_encoder.transform(['CL'])[0]]\nsubmission_df['Status_D'] = sub_preds[:, label_encoder.transform(['D'])[0]]\n\n# Ensure all columns are present even if a class wasn't predicted (though unlikely with proper training)\n# It's good practice to ensure all required output columns are there\nfor col in ['Status_C', 'Status_CL', 'Status_D']:\n    if col not in submission_df.columns:\n        submission_df[col] = 0.0 # Fill with 0.0 if somehow missing\n\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\nSubmission file created: submission.csv\")\nprint(submission_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T18:12:44.728467Z","iopub.execute_input":"2025-06-12T18:12:44.728873Z","iopub.status.idle":"2025-06-12T18:13:02.191426Z","shell.execute_reply.started":"2025-06-12T18:12:44.728848Z","shell.execute_reply":"2025-06-12T18:13:02.190479Z"}},"outputs":[{"name":"stdout","text":"\nStatus Label Encoding Mapping:\nC: 0\nCL: 1\nD: 2\n\nFeatures after scaling (Train DataFrame head):\n   Cholesterol     Stage  Edema_Y      SGOT  Spiders_Y  Tryglicerides  \\\n0    -0.316911 -0.028390    False  0.099439      False      -1.008015   \n1    -0.178669 -0.028390    False -0.939914      False      -0.658653   \n2     0.862212 -0.028390    False  0.923753      False       0.873168   \n3    -0.406362  1.119365    False -1.083273       True      -1.303630   \n4     0.374299 -1.176144    False  0.421996      False       1.115034   \n\n   Spiders_N  Drug_Placebo    Copper       Age  ...  Edema_S    N_Days  \\\n0       True         False -0.388831 -0.770118  ...    False  0.154784   \n1       True         False -0.755908 -0.401461  ...    False  0.504209   \n2       True          True -0.196553 -0.383028  ...    False  0.822891   \n3      False          True -0.511190 -0.020427  ...    False  0.183278   \n4       True          True  6.970182  0.606026  ...    False  0.213271   \n\n   Bilirubin  Ascites_N  Sex_M  Hepatomegaly_Y  Hepatomegaly_N  Alk_Phos  \\\n0  -0.503027       True  False           False            True -0.199980   \n1  -0.390871       True  False           False            True -0.518403   \n2  -0.278714       True  False           False            True  0.535638   \n3  -0.390871       True  False            True           False -0.396783   \n4   1.067161       True  False           False            True -0.309806   \n\n   Prothrombin  Drug_Missing  \n0    -1.403897         False  \n1     3.248734         False  \n2    -0.035476         False  \n3    -1.403897         False  \n4     0.511892         False  \n\n[5 rows x 23 columns]\n\nFeatures after scaling (Test DataFrame head):\n   Cholesterol     Stage  Edema_Y      SGOT  Spiders_Y  Tryglicerides  \\\n0    -0.178669  1.119365    False -0.115600      False      -0.148046   \n1    -0.178669 -1.176144    False -0.115600      False      -0.148046   \n2     1.285069 -0.028390    False -0.008080      False       0.362561   \n3    -0.357571 -1.176144    False -0.754934      False      -0.578030   \n4    -0.178669 -1.176144    False -0.115600      False      -0.148046   \n\n   Spiders_N  Drug_Placebo    Copper       Age  ...  Edema_S     N_Days  \\\n0      False         False -0.231513  0.881466  ...    False  15.502513   \n1      False         False -0.231513 -0.080466  ...    False   0.133038   \n2       True         False  0.170524 -0.855436  ...    False   1.408517   \n3       True         False -0.598589  0.277922  ...    False   0.335495   \n4      False         False -0.231513  1.073694  ...    False  -0.664042   \n\n   Bilirubin  Ascites_N  Sex_M  Hepatomegaly_Y  Hepatomegaly_N  Alk_Phos  \\\n0  -0.166558      False  False           False           False -0.227989   \n1  -0.353485      False  False           False           False -0.227989   \n2  -0.316100       True   True           False            True  0.565122   \n3  -0.465642       True  False           False            True -0.544939   \n4   0.955004      False  False           False           False -0.227989   \n\n   Prothrombin  Drug_Missing  \n0     0.511892          True  \n1    -2.224950          True  \n2    -0.035476         False  \n3     0.238208         False  \n4    -0.446003          True  \n\n[5 rows x 23 columns]\n\nOverall OOF LogLoss: 0.3779090218820752\n\nSubmission file created: submission.csv\n      id  Status_C  Status_CL  Status_D\n0  15000  0.403097   0.003545  0.593357\n1  15001  0.846374   0.015504  0.138122\n2  15002  0.699193   0.004245  0.296561\n3  15003  0.985702   0.000498  0.013800\n4  15004  0.215725   0.200202  0.584072\n","output_type":"stream"}],"execution_count":9}]}